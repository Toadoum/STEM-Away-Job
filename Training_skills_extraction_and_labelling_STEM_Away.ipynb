{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmCorlTvoqG8vVL5+eBhxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toadoum/STEM-Away-Job/blob/master/Training_skills_extraction_and_labelling_STEM_Away.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCTCFZMlgQ22",
        "outputId": "30259696-eed6-4523-f45c-e45ae1e054d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Latent Dirichlet Allocation (LDA)"
      ],
      "metadata": {
        "id": "L8O0V8Ll9LYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1dz-Gn_9Wkq",
        "outputId": "bc2f840e-10d0-4abf-bde3-1e628fb25111"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.7)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Building wheels for collected packages: pyLDAvis, sklearn\n",
            "  Building wheel for pyLDAvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=6277565c4904d98cdfae500cc3788daa59ff27f6f97568a64dcb8548456dc38e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/61/ec/9dbe9efc3acf9c4e37ba70fbbcc3f3a0ebd121060aa593181a\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=7bb0be31d4d9520ecf04d8422549211075f737c3d12ca84b9d8e556413e0f4fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built pyLDAvis sklearn\n",
            "Installing collected packages: sklearn, funcy, pyLDAvis\n",
            "Successfully installed funcy-1.17 pyLDAvis-3.3.1 sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Latent Dirichlet Allocation (LDA) to extract the most common topics from our data, and then use the top words from each topic as our skill_keywords."
      ],
      "metadata": {
        "id": "-TxVS8Ml_-pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/STEMAway/df_description_processed.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26TOIV9s9hEt",
        "outputId": "a209bfa8-39be-4baa-fdfa-8f3d48e044d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1006 entries, 0 to 1005\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Description         1006 non-null   object\n",
            " 1   lower_description   1006 non-null   object\n",
            " 2   word_tokenized      1006 non-null   object\n",
            " 3   sentence_tokenized  1006 non-null   object\n",
            " 4   word_count          1006 non-null   int64 \n",
            " 5   sentence_count      1006 non-null   int64 \n",
            " 6   clean_words         1006 non-null   object\n",
            " 7   clean_stemmed       1006 non-null   object\n",
            " 8   clean_lemmed        1006 non-null   object\n",
            "dtypes: int64(2), object(7)\n",
            "memory usage: 70.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the transform\n",
        "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.75)\n",
        "# tokenize and build vocab\n",
        "bag_of_words = vectorizer.fit_transform(df.clean_lemmed)\n",
        "# summarize\n",
        "sum_words = bag_of_words.sum(axis=0) \n",
        "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
        "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "words_freq[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G97DML8j9rR7",
        "outputId": "3a27c743-c900-4478-98f1-0ac8e7c49fd1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('model', 1942),\n",
              " ('ml', 1612),\n",
              " ('development', 1475),\n",
              " ('ai', 1437),\n",
              " ('business', 1431),\n",
              " ('skill', 1428),\n",
              " ('technology', 1419),\n",
              " ('product', 1416),\n",
              " ('research', 1382),\n",
              " ('engineering', 1371)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5379 documents represented as a 14,409 dimensional vector (14,409 words)\n",
        "bag_of_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMQ-tS2G9wli",
        "outputId": "36cd4752-0e72-40fb-a549-64e27f434767"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1006x15555 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 194431 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "LDA.fit(bag_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNitWDpq9z5F",
        "outputId": "c9cae36f-899c-44f9-9c7d-7273d70d4641"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=5, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_topic = LDA.components_[0]"
      ],
      "metadata": {
        "id": "Jj25ojxo93Q_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_topic_words = first_topic.argsort()[-10:]\n",
        "top_topic_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSWmWeug95dj",
        "outputId": "4366637b-28fa-4ac7-9cc4-df3e398a3665"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12981, 15289,  4967, 13890,  4198,  2396, 10867, 12815,  8972,\n",
              "        9026])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in top_topic_words:\n",
        "    print(vectorizer.get_feature_names()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlxxudBV98mG",
        "outputId": "e756220d-0734-4abd-9a27-9baa1e7c1752"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution\n",
            "working\n",
            "engineering\n",
            "technology\n",
            "development\n",
            "business\n",
            "product\n",
            "skill\n",
            "ml\n",
            "model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,topic in enumerate(LDA.components_):\n",
        "    print(f'Top 10 words for topic #{i}:')\n",
        "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q03mulDq-C3K",
        "outputId": "651dbbbd-97b4-44d3-c0c2-e25e71cc1473"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words for topic #0:\n",
            "['solution', 'working', 'engineering', 'technology', 'development', 'business', 'product', 'skill', 'ml', 'model']\n",
            "\n",
            "\n",
            "Top 10 words for topic #1:\n",
            "['support', 'skill', 'company', 'australia', 'abbvie', 'project', 'group', 'zealand', 'client', 'new']\n",
            "\n",
            "\n",
            "Top 10 words for topic #2:\n",
            "['year', 'computer', 'development', 'application', 'model', 'company', 'opportunity', 'business', 'product', 'technology']\n",
            "\n",
            "\n",
            "Top 10 words for topic #3:\n",
            "['technology', 'opportunity', 'engineer', 'development', 'company', 'engineering', 'business', 'solution', 'software', 'ai']\n",
            "\n",
            "\n",
            "Top 10 words for topic #4:\n",
            "['employment', 'candidate', 'position', 'development', 'student', 'computer', 'university', 'ai', 'application', 'research']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_values = LDA.transform(bag_of_words)\n",
        "topic_values.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-oRRqxE-GS4",
        "outputId": "b168a74b-a8bd-47a2-af12-3e1af939a165"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1006, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Topic'] = topic_values.argmax(axis=1)"
      ],
      "metadata": {
        "id": "OiF8fs85-KFU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "M9kmyhyJ-Oqg",
        "outputId": "bbe63aa9-a0db-4f91-945a-34fbc14e0d17"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Description  \\\n",
              "0  Job DescriptionBuild software, save the world!...   \n",
              "1  About The CompanyThis startup company has rece...   \n",
              "2  Anduril is a defence technology company, bring...   \n",
              "3  About RoktRokt is the global leader in eCommer...   \n",
              "4  Canva’s Commitment and MissionAt Canva, we cel...   \n",
              "\n",
              "                                   lower_description  \\\n",
              "0  job descriptionbuild software, save the world!...   \n",
              "1  about the companythis startup company has rece...   \n",
              "2  anduril is a defence technology company, bring...   \n",
              "3  about roktrokt is the global leader in ecommer...   \n",
              "4  canva’s commitment and missionat canva, we cel...   \n",
              "\n",
              "                                      word_tokenized  \\\n",
              "0  ['job', 'descriptionbuild', 'software', 'save'...   \n",
              "1  ['about', 'the', 'companythis', 'startup', 'co...   \n",
              "2  ['anduril', 'is', 'a', 'defence', 'technology'...   \n",
              "3  ['about', 'roktrokt', 'is', 'the', 'global', '...   \n",
              "4  ['canva', 's', 'commitment', 'and', 'missionat...   \n",
              "\n",
              "                                  sentence_tokenized  word_count  \\\n",
              "0  ['Job DescriptionBuild software, save the worl...         247   \n",
              "1  [\"About The CompanyThis startup company has re...         186   \n",
              "2  ['Anduril is a defence technology company, bri...         301   \n",
              "3  ['About RoktRokt is the global leader in eComm...        1237   \n",
              "4  ['Canva’s Commitment and MissionAt Canva, we c...         244   \n",
              "\n",
              "   sentence_count                                        clean_words  \\\n",
              "0               1  ['job', 'descriptionbuild', 'software', 'save'...   \n",
              "1               1  ['companythis', 'startup', 'company', 'receive...   \n",
              "2               7  ['anduril', 'defence', 'technology', 'company'...   \n",
              "3              36  ['roktrokt', 'global', 'leader', 'ecommerce', ...   \n",
              "4               6  ['canva', 'commitment', 'missionat', 'canva', ...   \n",
              "\n",
              "                                       clean_stemmed  \\\n",
              "0  ['job', 'descriptionbuild', 'softwar', 'save',...   \n",
              "1  ['companythi', 'startup', 'compani', 'receiv',...   \n",
              "2  ['anduril', 'defenc', 'technolog', 'compani', ...   \n",
              "3  ['roktrokt', 'global', 'leader', 'ecommerc', '...   \n",
              "4  ['canva', 'commit', 'missionat', 'canva', 'cel...   \n",
              "\n",
              "                                        clean_lemmed  Topic  \n",
              "0  ['job', 'descriptionbuild', 'software', 'save'...      3  \n",
              "1  ['companythis', 'startup', 'company', 'receive...      0  \n",
              "2  ['anduril', 'defence', 'technology', 'company'...      0  \n",
              "3  ['roktrokt', 'global', 'leader', 'ecommerce', ...      3  \n",
              "4  ['canva', 'commitment', 'missionat', 'canva', ...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6acdc26-e258-4e78-b121-d3dccaf2a391\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>lower_description</th>\n",
              "      <th>word_tokenized</th>\n",
              "      <th>sentence_tokenized</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>clean_words</th>\n",
              "      <th>clean_stemmed</th>\n",
              "      <th>clean_lemmed</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Job DescriptionBuild software, save the world!...</td>\n",
              "      <td>job descriptionbuild software, save the world!...</td>\n",
              "      <td>['job', 'descriptionbuild', 'software', 'save'...</td>\n",
              "      <td>['Job DescriptionBuild software, save the worl...</td>\n",
              "      <td>247</td>\n",
              "      <td>1</td>\n",
              "      <td>['job', 'descriptionbuild', 'software', 'save'...</td>\n",
              "      <td>['job', 'descriptionbuild', 'softwar', 'save',...</td>\n",
              "      <td>['job', 'descriptionbuild', 'software', 'save'...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>About The CompanyThis startup company has rece...</td>\n",
              "      <td>about the companythis startup company has rece...</td>\n",
              "      <td>['about', 'the', 'companythis', 'startup', 'co...</td>\n",
              "      <td>[\"About The CompanyThis startup company has re...</td>\n",
              "      <td>186</td>\n",
              "      <td>1</td>\n",
              "      <td>['companythis', 'startup', 'company', 'receive...</td>\n",
              "      <td>['companythi', 'startup', 'compani', 'receiv',...</td>\n",
              "      <td>['companythis', 'startup', 'company', 'receive...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anduril is a defence technology company, bring...</td>\n",
              "      <td>anduril is a defence technology company, bring...</td>\n",
              "      <td>['anduril', 'is', 'a', 'defence', 'technology'...</td>\n",
              "      <td>['Anduril is a defence technology company, bri...</td>\n",
              "      <td>301</td>\n",
              "      <td>7</td>\n",
              "      <td>['anduril', 'defence', 'technology', 'company'...</td>\n",
              "      <td>['anduril', 'defenc', 'technolog', 'compani', ...</td>\n",
              "      <td>['anduril', 'defence', 'technology', 'company'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>About RoktRokt is the global leader in eCommer...</td>\n",
              "      <td>about roktrokt is the global leader in ecommer...</td>\n",
              "      <td>['about', 'roktrokt', 'is', 'the', 'global', '...</td>\n",
              "      <td>['About RoktRokt is the global leader in eComm...</td>\n",
              "      <td>1237</td>\n",
              "      <td>36</td>\n",
              "      <td>['roktrokt', 'global', 'leader', 'ecommerce', ...</td>\n",
              "      <td>['roktrokt', 'global', 'leader', 'ecommerc', '...</td>\n",
              "      <td>['roktrokt', 'global', 'leader', 'ecommerce', ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canva’s Commitment and MissionAt Canva, we cel...</td>\n",
              "      <td>canva’s commitment and missionat canva, we cel...</td>\n",
              "      <td>['canva', 's', 'commitment', 'and', 'missionat...</td>\n",
              "      <td>['Canva’s Commitment and MissionAt Canva, we c...</td>\n",
              "      <td>244</td>\n",
              "      <td>6</td>\n",
              "      <td>['canva', 'commitment', 'missionat', 'canva', ...</td>\n",
              "      <td>['canva', 'commit', 'missionat', 'canva', 'cel...</td>\n",
              "      <td>['canva', 'commitment', 'missionat', 'canva', ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6acdc26-e258-4e78-b121-d3dccaf2a391')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6acdc26-e258-4e78-b121-d3dccaf2a391 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6acdc26-e258-4e78-b121-d3dccaf2a391');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import pyLDAvis\n",
        "sns.set()\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "import gensim\n",
        "\n",
        "\n",
        "# import nltk\n",
        "# from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "# from nltk.stem.porter import PorterStemmer\n",
        "# from nltk.stem.wordnet import WordNetLemmatizer\n",
        "# from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuVCek6t9KF5",
        "outputId": "f7b9ca7e-801b-419e-9304-1dce19f8cd78"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.8/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Mapping\n",
            "/usr/local/lib/python3.8/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmN3kcVMfh9_",
        "outputId": "f44c2b9f-a624-4e71-ec99-9f63f2e40c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length: 128710 Sample Size: 12871.0\n",
            "Length: 130592 Sample Size: 13059.2\n",
            "Length: 65436 Sample Size: 6543.6\n",
            "Length: 6478 Sample Size: 647.8000000000001\n",
            "'train_skills.csv' has been created\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# chunks were taken from regex of POS tags located on google colab\n",
        "chunks1 = pickle.load( open('/content/drive/My Drive/STEMAway/chunks_1.pickle', \"rb\" ) )\n",
        "chunks2 = pickle.load( open('/content/drive/My Drive/STEMAway/chunks_2.pickle', \"rb\" ) )\n",
        "chunks3 = pickle.load( open('/content/drive/My Drive/STEMAway/chunks_3.pickle', \"rb\" ) )\n",
        "chunks4 = pickle.load( open('/content/drive/My Drive/STEMAway/chunks_4.pickle', \"rb\" ) )\n",
        "\n",
        "# Sample size is 10% and will be labeled accordingly\n",
        "# perhaps a sample of a sample can be used depends on NN model\n",
        "print('Length:', len(chunks1), 'Sample Size:', len(chunks1) * .10)\n",
        "print('Length:', len(chunks2), 'Sample Size:', len(chunks2) * .10) \n",
        "print('Length:', len(chunks3), 'Sample Size:', len(chunks3) * .10)\n",
        "print('Length:', len(chunks4), 'Sample Size:', len(chunks4) * .10)\n",
        "\n",
        "def training_set(chunks):\n",
        "    '''creates a dataframe that easily parsed with the chunks data '''\n",
        "    df = pd.DataFrame(chunks)    \n",
        "    df.fillna('X', inplace = True)\n",
        "    \n",
        "    train = []\n",
        "    for row in df.values:\n",
        "        phrase = ''\n",
        "        for tup in row:\n",
        "            # needs a space at the end for seperation\n",
        "            phrase += tup[0] + ' '\n",
        "        phrase = ''.join(phrase)\n",
        "        # could use padding tages but encoder method will provide during \n",
        "        # tokenizing/embeddings; X can replace paddding for now\n",
        "        train.append( phrase.replace('X', '').strip())\n",
        "\n",
        "    df['phrase'] = train\n",
        "\n",
        "    # only returns 10% of each dataframe to be used \n",
        "    return df.phrase.sample(frac = 0.1)\n",
        "\n",
        "# one training corpus with 10% of each POS regex identification\n",
        "training = pd.concat([training_set(chunks1),\n",
        "                      training_set(chunks2), \n",
        "                      training_set(chunks3),\n",
        "                      training_set(chunks4)], \n",
        "                        ignore_index = True )\n",
        "\n",
        "training.to_csv('train_skills.csv')\n",
        "print(\"'train_skills.csv' has been created\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the top words for each topic\n",
        "top_words = []\n",
        "for index, topic in enumerate(LDA.components_):\n",
        "    top_words.extend([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
        "\n",
        "# Remove duplicates\n",
        "skill_keywords = list(set(top_words))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2qI8A0U8m1r",
        "outputId": "006dd34a-e8b9-4f80-a5b0-300b01ea62a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skill_keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn98JhSZ8pn4",
        "outputId": "d8513a5b-d054-4e67-f164-25b592c8df21"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['new',\n",
              " 'student',\n",
              " 'year',\n",
              " 'skill',\n",
              " 'solution',\n",
              " 'business',\n",
              " 'ml',\n",
              " 'software',\n",
              " 'university',\n",
              " 'employment',\n",
              " 'project',\n",
              " 'ai',\n",
              " 'company',\n",
              " 'group',\n",
              " 'abbvie',\n",
              " 'technology',\n",
              " 'engineer',\n",
              " 'model',\n",
              " 'candidate',\n",
              " 'support',\n",
              " 'product',\n",
              " 'opportunity',\n",
              " 'australia',\n",
              " 'development',\n",
              " 'engineering',\n",
              " 'client',\n",
              " 'application',\n",
              " 'computer',\n",
              " 'zealand',\n",
              " 'position',\n",
              " 'research',\n",
              " 'working']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After doing Latent Dirichlet Allocation (LDA), we can extract the top words from each topic as our skill_keywords."
      ],
      "metadata": {
        "id": "FWvw3G1_AMMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train_skills.csv')\n",
        "\n",
        "# Create an empty column called \"skill\"\n",
        "df['skill'] = 0\n",
        "\n",
        "# Define a list of keywords that represent skills\n",
        "skill_keywords = skill_keywords\n",
        "# Iterate over the phrases in the dataset\n",
        "for i, row in df.iterrows():\n",
        "    phrase = row['phrase']\n",
        "    skill = 0\n",
        "    # Check if any of the keywords are present in the phrase\n",
        "    for keyword in skill_keywords:\n",
        "        if keyword in phrase:\n",
        "            skill = 1\n",
        "            break\n",
        "    # Update the \"skill\" column with the value of 1 or 0\n",
        "    df.at[i, 'skill'] = skill\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "df.to_csv('train_skills_labeled.csv', index=False)\n",
        "print(\"'train_skills_labeled.csv' has been created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEPfZh_s7kXn",
        "outputId": "019bbccc-5e1a-4633-ebd3-a6692135aedb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'train_skills_labeled.csv' has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DpVyoEZr_HBC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}